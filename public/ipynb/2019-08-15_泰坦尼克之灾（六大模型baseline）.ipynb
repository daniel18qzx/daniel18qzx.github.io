{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: 泰坦尼克之灾（六大模型baseline）\n",
    "date: 2019-08-15\n",
    "categories: [人工智能, 项目]\n",
    "mathjax: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集载入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:19.562488Z",
     "start_time": "2019-08-23T14:06:19.533837Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"2019-08-15_泰坦尼克之灾_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:20.409750Z",
     "start_time": "2019-08-23T14:06:20.402615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:21.254602Z",
     "start_time": "2019-08-23T14:06:21.245656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64格式共有5个: ['PassengerId', 'Survived', 'Pclass', 'SibSp', 'Parch']\n",
      "\n",
      "object格式共有5个: ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "\n",
      "float64格式共有2个: ['Age', 'Fare']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "typedic = {} # 类型字典\n",
    "for name in df.columns:\n",
    "    typedic[str(df[name].dtype)] = typedic.get(str(df[name].dtype),[])+[name]\n",
    "\n",
    "for key,value in typedic.items():\n",
    "    print(\"{}格式共有{}个: {}\".format(key,len(value),value))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此可以看到数据不全的有：['Age','Cabin']\n",
    "\n",
    "需要调整类型或删除无用资讯的包含：['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:22.094937Z",
     "start_time": "2019-08-23T14:06:22.085839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Survived.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:23.402628Z",
     "start_time": "2019-08-23T14:06:22.919283Z"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(3, 3, figsize=(20, 10))\n",
    "\n",
    "# 年龄以20-40为主，5岁以下密度有局部高峰\n",
    "x = df['Age'].dropna()\n",
    "sns.distplot(x, ax = ax[0][0])\n",
    "\n",
    "# 存活率大约为3分之2\n",
    "sns.countplot(x = 'Survived', data = df, ax = ax[0][1])\n",
    "\n",
    "# 年龄跟舱等的分布\n",
    "df['Age'][df.Pclass == 1].plot(kind='kde', ax = ax[0][2])\n",
    "df['Age'][df.Pclass == 2].plot(kind='kde', ax = ax[0][2])\n",
    "df['Age'][df.Pclass == 3].plot(kind='kde', ax = ax[0][2])\n",
    "\n",
    "# 以三舱等为主\n",
    "sns.countplot(x = 'Pclass', data = df, ax = ax[1][0])\n",
    "\n",
    "# 登船口岸以S为大宗\n",
    "sns.countplot(x = 'Embarked', data = df, ax = ax[1][1])\n",
    "\n",
    "# 性别男生为主\n",
    "sns.countplot(x = 'Sex', data = df, ax = ax[1][2])\n",
    "\n",
    "plt.savefig(\"../img/2019-08-15_泰坦尼克之灾_1.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](/img/2019-08-15_泰坦尼克之灾_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:24.507323Z",
     "start_time": "2019-08-23T14:06:24.234798Z"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 2, figsize=(20, 10))\n",
    "\n",
    "# 按年龄看获救情况，老人没获救比例高\n",
    "sns.stripplot(x = 'Survived', y ='Age', data = df, ax = ax[0][0])\n",
    "\n",
    "# 按舱等看获救情况，3舱等大都没获救\n",
    "sns.countplot(x = 'Survived', hue ='Pclass', data = df, ax = ax[0][1])\n",
    "\n",
    "# 按登船口岸看获救情况，S登船的大都没被获救\n",
    "sns.countplot(x = 'Survived', hue = 'Embarked', data = df, ax = ax[1][0])\n",
    "\n",
    "# 按登船口岸看获救情况，男生大都没被获救\n",
    "sns.countplot(x = 'Survived', hue = 'Sex', data = df, ax = ax[1][1])\n",
    "\n",
    "plt.savefig(\"../img/2019-08-15_泰坦尼克之灾_2.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](/img/2019-08-15_泰坦尼克之灾_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:25.282250Z",
     "start_time": "2019-08-23T14:06:25.263427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>423</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Zimmerman, Mr. Leo</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315082</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>508</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bradley, Mr. George (\"George Arthur Brayton\")</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111427</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Yousif, Mr. Wazli</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2647</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moore, Mr. Leonard Charles</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A4. 54510</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Olsen, Mr. Karl Siegwart Andreas</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4579</td>\n",
       "      <td>8.4042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Hood, Mr. Ambrose Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S.O.C. 14879</td>\n",
       "      <td>73.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Holverson, Mr. Alexander Oskar</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113789</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>745</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Stranden, Mr. Juho</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101288</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>518</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Ryan, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>371110</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>389</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sadlier, Mr. Matthew</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>367655</td>\n",
       "      <td>7.7292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "422          423         0       3   \n",
       "507          508         1       1   \n",
       "354          355         0       3   \n",
       "121          122         0       3   \n",
       "197          198         0       3   \n",
       "72            73         0       2   \n",
       "35            36         0       1   \n",
       "744          745         1       3   \n",
       "517          518         0       3   \n",
       "388          389         0       3   \n",
       "\n",
       "                                              Name   Sex   Age  SibSp  Parch  \\\n",
       "422                             Zimmerman, Mr. Leo  male  29.0      0      0   \n",
       "507  Bradley, Mr. George (\"George Arthur Brayton\")  male   NaN      0      0   \n",
       "354                              Yousif, Mr. Wazli  male   NaN      0      0   \n",
       "121                     Moore, Mr. Leonard Charles  male   NaN      0      0   \n",
       "197               Olsen, Mr. Karl Siegwart Andreas  male  42.0      0      1   \n",
       "72                            Hood, Mr. Ambrose Jr  male  21.0      0      0   \n",
       "35                  Holverson, Mr. Alexander Oskar  male  42.0      1      0   \n",
       "744                             Stranden, Mr. Juho  male  31.0      0      0   \n",
       "517                              Ryan, Mr. Patrick  male   NaN      0      0   \n",
       "388                           Sadlier, Mr. Matthew  male   NaN      0      0   \n",
       "\n",
       "                Ticket     Fare Cabin Embarked  \n",
       "422             315082   7.8750   NaN        S  \n",
       "507             111427  26.5500   NaN        S  \n",
       "354               2647   7.2250   NaN        C  \n",
       "121          A4. 54510   8.0500   NaN        S  \n",
       "197               4579   8.4042   NaN        S  \n",
       "72        S.O.C. 14879  73.5000   NaN        S  \n",
       "35              113789  52.0000   NaN        S  \n",
       "744  STON/O 2. 3101288   7.9250   NaN        S  \n",
       "517             371110  24.1500   NaN        Q  \n",
       "388             367655   7.7292   NaN        Q  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tuned = df.copy(deep=True)\n",
    "df_tuned.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除无用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:26.104112Z",
     "start_time": "2019-08-23T14:06:26.100286Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tuned = df_tuned.drop(['Name'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 填充空值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:26.905554Z",
     "start_time": "2019-08-23T14:06:26.900351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "19.865319865319865\n"
     ]
    }
   ],
   "source": [
    "# 有177个缺失,将近2成\n",
    "print(df_tuned['Age'].isnull().sum())\n",
    "print(df_tuned['Age'].isnull().sum() * 100 / df_tuned.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:27.755013Z",
     "start_time": "2019-08-23T14:06:27.745622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "feature = df_tuned['Age'].values.reshape(-1,1)\n",
    "imp_mode = Imputer(strategy = 'most_frequent')\n",
    "df_tuned['Age'] = np.mean(imp_mode.fit_transform(feature))\n",
    "\n",
    "# 现在无缺失了\n",
    "print(df_tuned['Age'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:29.924589Z",
     "start_time": "2019-08-23T14:06:28.742414Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tuned['Cabin'][df_tuned['Cabin'].isnull()] = 0\n",
    "df_tuned['Cabin'][df_tuned['Cabin'].notnull()] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理分类特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin, Embarked, Sex, Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:30.774671Z",
     "start_time": "2019-08-23T14:06:30.761503Z"
    }
   },
   "outputs": [],
   "source": [
    "dummies_Cabin = pd.get_dummies(df_tuned['Cabin'], prefix= 'Cabin')\n",
    "dummies_Embarked = pd.get_dummies(df_tuned['Embarked'], prefix= 'Embarked')\n",
    "dummies_Sex = pd.get_dummies(df_tuned['Sex'], prefix= 'Sex')\n",
    "dummies_Pclass = pd.get_dummies(df_tuned['Pclass'], prefix= 'Pclass')\n",
    "\n",
    "df_tuned = pd.concat([df_tuned, dummies_Cabin, dummies_Embarked, dummies_Sex, dummies_Pclass], axis=1)\n",
    "df_tuned.drop(['Pclass', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:31.613734Z",
     "start_time": "2019-08-23T14:06:31.606542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Fare           891 non-null float64\n",
      "Cabin_1        891 non-null uint8\n",
      "Embarked_C     891 non-null uint8\n",
      "Embarked_Q     891 non-null uint8\n",
      "Embarked_S     891 non-null uint8\n",
      "Sex_female     891 non-null uint8\n",
      "Sex_male       891 non-null uint8\n",
      "Pclass_1       891 non-null uint8\n",
      "Pclass_2       891 non-null uint8\n",
      "Pclass_3       891 non-null uint8\n",
      "dtypes: float64(2), int64(4), uint8(9)\n",
      "memory usage: 49.7 KB\n"
     ]
    }
   ],
   "source": [
    "# 最后检查\n",
    "df_tuned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:32.465321Z",
     "start_time": "2019-08-23T14:06:32.458628Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_tuned[:].drop(\"Survived\",axis=1)\n",
    "y = df_tuned[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:33.265865Z",
     "start_time": "2019-08-23T14:06:33.257030Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "data = ss.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(data,columns = X.columns)\n",
    "\n",
    "data = ss.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(data,columns = X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:34.200272Z",
     "start_time": "2019-08-23T14:06:34.059551Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "LR = LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n",
    "LR = LR.fit(X_train, y_train)\n",
    "# LR = cross_val_score(LR, X_train, y_train, cv = 5)\n",
    "\n",
    "svc = SVC(kernel='linear', probability = True)\n",
    "svc = svc.fit(X_train, y_train)\n",
    "# svc = cross_val_score(svc,X_train,y_train, cv = 5)\n",
    "\n",
    "DT = DecisionTreeClassifier(max_depth = 6)\n",
    "DT = DT.fit(X_train, y_train)\n",
    "# DT = cross_val_score(DT, X_train, y_train, cv = 5)\n",
    "\n",
    "RF = RandomForestClassifier()\n",
    "RF = RF.fit(X_train, y_train)\n",
    "# RF = cross_val_score(RF, X_train, y_train, cv = 5)\n",
    "\n",
    "KNN = KNeighborsClassifier()\n",
    "KNN = KNN.fit(X_train, y_train)\n",
    "# LR = cross_val_score(LR, X_train, y_train, cv = 5)\n",
    "\n",
    "GBDT = GradientBoostingClassifier()\n",
    "GBDT = GBDT.fit(X_train, y_train)\n",
    "# LR = cross_val_score(LR, X_train, y_train, cv = 5)\n",
    "\n",
    "names = [\"LR\", \"SVC\", 'DT', \"RF\", \"KNN\", \"GBDT\"]\n",
    "models = [LR, svc, DT, RF, KNN, GBDT]\n",
    "evaluates = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:54.592936Z",
     "start_time": "2019-08-23T14:06:54.464591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LR</th>\n",
       "      <th>train</th>\n",
       "      <td>0.800562</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.676259</td>\n",
       "      <td>0.725869</td>\n",
       "      <td>0.838942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.747967</td>\n",
       "      <td>0.844158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVC</th>\n",
       "      <th>train</th>\n",
       "      <td>0.783708</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.683453</td>\n",
       "      <td>0.711610</td>\n",
       "      <td>0.819083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>0.804755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DT</th>\n",
       "      <th>train</th>\n",
       "      <td>0.856742</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.776978</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.909753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.836141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">RF</th>\n",
       "      <th>train</th>\n",
       "      <td>0.984551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960432</td>\n",
       "      <td>0.979817</td>\n",
       "      <td>0.999631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.700855</td>\n",
       "      <td>0.874117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">KNN</th>\n",
       "      <th>train</th>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.705036</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.910006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.730435</td>\n",
       "      <td>0.856590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">GBDT</th>\n",
       "      <th>train</th>\n",
       "      <td>0.883427</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.776978</td>\n",
       "      <td>0.838835</td>\n",
       "      <td>0.949446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.876019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accuracy  Precision    Recall  F1-Score  AUC-Score\n",
       "LR   train  0.800562   0.783333  0.676259  0.725869   0.838942\n",
       "     test   0.826816   0.779661  0.718750  0.747967   0.844158\n",
       "SVC  train  0.783708   0.742188  0.683453  0.711610   0.819083\n",
       "     test   0.798883   0.741379  0.671875  0.704918   0.804755\n",
       "DT   train  0.856742   0.843750  0.776978  0.808989   0.909753\n",
       "     test   0.837989   0.807018  0.718750  0.760331   0.836141\n",
       "RF   train  0.984551   1.000000  0.960432  0.979817   0.999631\n",
       "     test   0.804469   0.773585  0.640625  0.700855   0.874117\n",
       "KNN  train  0.832865   0.841202  0.705036  0.767123   0.910006\n",
       "     test   0.826816   0.823529  0.656250  0.730435   0.856590\n",
       "GBDT train  0.883427   0.911392  0.776978  0.838835   0.949446\n",
       "     test   0.849162   0.824561  0.734375  0.776860   0.876019"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = []\n",
    "for name,model in zip(names,models):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    #accuracy\n",
    "    train_accuracy = model.score(X_train,y_train)\n",
    "    test_accuracy = model.score(X_test,y_test)\n",
    "    \n",
    "    \n",
    "    #precision   \n",
    "    train_precision = precision_score(y_train,y_train_pred)\n",
    "    test_precision = precision_score(y_test,y_test_pred)   \n",
    "    \n",
    "    #recall\n",
    "    train_recall = recall_score(y_train,y_train_pred)\n",
    "    test_recall = recall_score(y_test,y_test_pred)   \n",
    "    \n",
    "    #f1\n",
    "    train_f1 = f1_score(y_train,y_train_pred)\n",
    "    test_f1 = f1_score(y_test,y_test_pred)   \n",
    "    \n",
    "    #auc\n",
    "    y_train_pred = model.predict_proba(X_train)[:,1]\n",
    "    y_test_pred = model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    train_auc = roc_auc_score(y_train,y_train_pred)\n",
    "    test_auc = roc_auc_score(y_test,y_test_pred)\n",
    "    \n",
    "#     print('{} 训练集： accuracy:{:.3},precision:{:.3}, recall:{:.3}, f1:{:.3}, auc:{:.3}'.format(name,train_accuracy,train_precision,train_recall,train_f1,train_auc))\n",
    "#     print('{} 测试集： accuracy:{:.3},precision:{:.3}, recall:{:.3}, f1:{:.3}, auc:{:.3}'.format(name,test_accuracy,test_precision,test_recall,test_f1,test_auc))\n",
    "#     print('\\n')\n",
    "    df = pd.DataFrame(np.array([train_accuracy,train_precision,train_recall,train_f1,train_auc,test_accuracy,test_precision,test_recall,test_f1,test_auc]).reshape(2,-1),\n",
    "                  index = ['train','test'],\n",
    "                  columns = ['Accuracy','Precision','Recall','F1-Score','AUC-Score'])\n",
    "    df_list.append(df)\n",
    "\n",
    "pd.concat(df_list,axis=0,keys=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:06:40.198249Z",
     "start_time": "2019-08-23T14:06:39.178763Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"2019-08-15_泰坦尼克之灾_test.csv\")\n",
    "df_tuned_test = df_test.copy(deep=True)\n",
    "\n",
    "df_tuned_test = df_tuned_test.drop(['Name'],axis=1)\n",
    "\n",
    "feature = df_tuned_test['Age'].values.reshape(-1,1)\n",
    "imp_mode = Imputer(strategy = 'most_frequent')\n",
    "df_tuned_test['Age'] = np.mean(imp_mode.fit_transform(feature))\n",
    "\n",
    "feature = df_tuned_test['Fare'].values.reshape(-1,1)\n",
    "imp_mode = Imputer(strategy = 'most_frequent')\n",
    "df_tuned_test['Fare'] = np.mean(imp_mode.fit_transform(feature))\n",
    "\n",
    "df_tuned_test['Cabin'][df_tuned_test['Cabin'].isnull()] = 0\n",
    "df_tuned_test['Cabin'][df_tuned_test['Cabin'].notnull()] = 1\n",
    "\n",
    "dummies_Cabin = pd.get_dummies(df_tuned_test['Cabin'], prefix= 'Cabin')\n",
    "dummies_Embarked = pd.get_dummies(df_tuned_test['Embarked'], prefix= 'Embarked')\n",
    "dummies_Sex = pd.get_dummies(df_tuned_test['Sex'], prefix= 'Sex')\n",
    "dummies_Pclass = pd.get_dummies(df_tuned_test['Pclass'], prefix= 'Pclass')\n",
    "\n",
    "df_tuned_test = pd.concat([df_tuned_test, dummies_Cabin, dummies_Embarked, dummies_Sex, dummies_Pclass], axis=1)\n",
    "df_tuned_test.drop(['Pclass', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "data = ss.fit_transform(df_tuned_test)\n",
    "df_tuned_test = pd.DataFrame(data,columns = df_tuned_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T14:03:47.088983Z",
     "start_time": "2019-08-23T14:03:47.080002Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = GBDT.predict(df_tuned_test)\n",
    "result = pd.DataFrame({'PassengerId':df_test['PassengerId'].as_matrix(), 'Survived':predictions.astype(np.int32)})\n",
    "result.to_csv(\"2019-08-15_泰坦尼克之灾_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "184px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
