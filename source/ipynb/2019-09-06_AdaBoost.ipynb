{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: AdaBoost\n",
    "date: 2019-09-06\n",
    "categories: [人工智能, 监督学习]\n",
    "mathjax: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 初始化训练数据的权值分布。每⼀个训练样本最开始时都被赋予相同的权值：1/N\n",
    "2. 进⾏多轮迭代，⽤m = 1,2, ..., M表⽰迭代的第多少轮\n",
    "    - 使⽤具有权值分布Dm的训练数据集学习，得到基本分类器（选取让误差率最低的阈值来设计基本分类器）\n",
    "    - 计算Gm(x)在训练数据集上的分类误差率，Gm(x)在训练数据集上的误差率em就是被Gm(x)误分类样本的权值之和\n",
    "$$e_m=\\sum_{N}^{i=1}{w_{mi}I(G_m(x_i)\\neq y_i)}$$\n",
    "    - 计算Gm(x)的系数，am表⽰Gm(x)在最终分类器中的重要程度（⽬的：得到基本分类器在最终分类器中所占的权重）：\n",
    "$$\\alpha_m={\\frac{1}{2}}log{\\frac{1-e_m}{e_m}}$$\n",
    "em <= 1/2时，am >= 0，且am随着em的减⼩⽽增⼤，意味着分类误差率越⼩的基本分类器在最终分类器中的作⽤越⼤\n",
    "    - 更新训练数据集的权值分布（为了得到样本的新的权值分布），⽤于下⼀轮迭代，使得被基本分类器Gm(x)误分类样本的权值增⼤，⽽被正确分类样本的权值减⼩  \n",
    "3. 组合各个弱分类器，从⽽得到最终分类器\n",
    "$$G(x)=sign(f(x))=sign(\\sum_{m=1}^{M}\\alpha_m G_m(x))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:04:00.921923Z",
     "start_time": "2019-09-09T13:03:59.561130Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier  \n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_data = iris['data']\n",
    "iris_label = iris['target']\n",
    "iris_target_name = iris['target_names']\n",
    "X = np.array(iris_data)\n",
    "Y = np.array(iris_label)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "clf = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:04:39.417479Z",
     "start_time": "2019-09-09T13:04:39.377968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9225589225589226"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(\n",
    "    y_test, y_pred, pos_label=2)\n",
    "\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- base_estimator: 基分类器，默认是决策树，在该分类器基础上进行boosting，理论上可以是任意一个分类器，但是如果是其他分类器时需要指明样本权重\n",
    "- n_estimators: 基分类器提升（循环）次数，默认是50次，这个值过大，模型容易过拟合；值过小，模型容易欠拟合\n",
    "- learning_rate: 学习率，表示梯度收敛速度，默认为1，如果过大，容易错过最优值，如果过小，则收敛速度会很慢；该值需要和n_estimators进行一个权衡，当分类器迭代次数较少时，学习率可以小一些，当迭代次数较多时，学习率可以适当放大\n",
    "- algorithm: boosting算法，也就是模型提升准则，有两种方式SAMME, 和SAMME.R两种，默认是SAMME.R，两者的区别主要是弱学习器权重的度量，前者是对样本集预测错误的概率进行划分的，后者是对样本集的预测错误的比例，即错分率进行划分的，默认是用的SAMME.R\n",
    "- random_state: 随机种子设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 参考：\n",
    "\n",
    "1. [从机器学习到深度学习：基于Scikit-learn与TensorFlow的高效开发实战](http://www.broadview.com.cn/book/5337)\n",
    "2. [AdaBoost原理详解](https://www.cnblogs.com/ScorpioLu/p/8295990.html)\n",
    "3. [AdaBoostClassifier参数](https://www.cnblogs.com/mdevelopment/p/9445090.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "267px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
