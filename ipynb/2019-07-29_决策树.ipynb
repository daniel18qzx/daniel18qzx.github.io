{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: 决策树\n",
    "date: 2019-07-29\n",
    "categories: [人工智能, 监督学习]\n",
    "mathjax: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 分而治之(divide-andconquer)：\n",
    "    - 自根至叶的递归过程\n",
    "    - 在每个中间结点寻找一个\"划分\"属性\n",
    "    \n",
    "\n",
    "- 过程：\n",
    "    - 把数据集分成两组\n",
    "    - 不同数据点被完美区分（Pure）开了么？\n",
    "    - 不是：重复楼上两步\n",
    "    - 是的：打完收⼯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建树逻辑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有子树信息价值（信息熵、基尼指数等）的和必定小于等于原来整体数据集的信息价值，信息增益用来衡量减少的程度\n",
    "\n",
    "> def build(D=数据集)：\n",
    ">\n",
    "> 　　if D所有数据目标值 y 都相同：\n",
    ">\n",
    "> 　　　　return  #递回停止条件\n",
    ">\n",
    "> 　　for i in D中的所有特征：\n",
    ">\n",
    "> 　　　　计算用i划分子树后获得的信息增益\n",
    ">\n",
    "> 　　if 所有特征都没有大于零的信息增益：\n",
    ">\n",
    "> 　　　　return  #递回停止条件\n",
    ">\n",
    "> 　　被选择的特征 x = 具有最大信息增益的特征\n",
    ">\n",
    "> 　　for sub in 按照x划分子树后的数据集：\n",
    ">\n",
    "> 　　　　build(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 停止条件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 当前结点包含的样本全属于同一类别，无须划分\n",
    "- 当前属性集为空，或是所有样本在所有属性上取值相同，无法划分\n",
    "- 当前结点包含的样本集合为空，不能划分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 优势：\n",
    "    - ⾮⿊盒\n",
    "    - 轻松去除⽆关attribute (Gain = 0)\n",
    "    - Test起来很快 (O(depth))\n",
    "\n",
    "\n",
    "- 劣势：\n",
    "    - 只能线性分割数据\n",
    "    - 贪婪算法 (每次分裂都选最好，有可能不是全局最好)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信息价值指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信息熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息熵是度量样本集合\"纯度\"最常用的一种指标，假定当前样本集合D中第i类样本所占的比例为$P_i$，则D的信息熵定义为：\n",
    "\n",
    "$$Ent(D)=-\\sum_{i=1}^{n}{P_i \\cdot log{P_i}}$$\n",
    "\n",
    "- 某随机事件结果的种类越多，则该事件的熵越大（不确定性越大）\n",
    "- 某随机事件的各种可能发生结果概率越均匀，则该事件的熵越大（不确定性越大）\n",
    "- 值域：>= 0\n",
    "- 缺点是计算量大（log）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信息增益(ID3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Gain(D,a)=Ent(D)-\\sum_{i=1}^{n}{\\frac{|D^i|}{|D|}{Ent(D^i)}}$$\n",
    "\n",
    "- 划分前的信息熵-划分后的总信息熵\n",
    "- 越大越好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信息增益率(C4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$GainRatio(D,a)=\\frac{Gain(D,a)}{IV(a)}$$\n",
    "\n",
    "$$IV(a)=-\\sum_{i=1}^{i}{\\frac{|D^i|}{|D|}{log_2{\\frac{|D^i|}{|D|}}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基尼指数(CART)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$G=1-\\sum_{i=1}^{n}{P_i^2}$$\n",
    "\n",
    "- 值域：0~1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常见算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ID3：    \n",
    "    - 只能使用熵的信息增益处理离散特征的分类问题\n",
    "    - 取值高的属性，更容易使数据更纯，其信息增益更大\n",
    "    - 训练得到的是一棵庞大且深度浅的树（可以把N个数据分成100%纯洁的N组）\n",
    "\n",
    "\n",
    "- C4.5：\n",
    "    - 支持连续特征，在计算信息增益比之前首先将其离散化（与ID3差别）\n",
    "    - 使用信息增益比的概念去除先选择多值特征的倾向\n",
    "    - 在训练后检测训练集的正确分类比，并剪枝产生错误较多的叶子结点\n",
    "\n",
    "\n",
    "- CART算法：\n",
    "    - 使用基尼系数代替熵进行信息增益计算、只使用二叉树，并提供解决回归问题的能力\n",
    "    - 以最小化不纯度，而不是最大化信息增益"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T12:33:52.873455Z",
     "start_time": "2019-09-09T12:33:51.778744Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_data = iris['data']\n",
    "iris_label = iris['target']\n",
    "iris_target_name = iris['target_names']\n",
    "X = np.array(iris_data)\n",
    "Y = np.array(iris_label)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T12:33:52.951697Z",
     "start_time": "2019-09-09T12:33:52.944504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(\n",
    "    y_test, y_pred, pos_label=2)\n",
    "\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "超参数：\n",
    "- criterion: gini, entropy\n",
    "- max_depth\n",
    "- min_samples_split\n",
    "- min_samples_leaf\n",
    "- max_features\n",
    "- max_leaf_nodes\n",
    "- min_impurity_decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_depth\n",
    "\n",
    "要调整的第一个参数是max_depth（树的深度）。 树越深，它就分裂的越多，更能捕获有关数据的信息。 我们拟合一个深度范围从1到32的决策树，并绘制训练和测试auc分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T12:34:17.307147Z",
     "start_time": "2019-09-09T12:34:17.159782Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    dt = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    dt.fit(x_train, y_train)\n",
    "    train_pred = dt.predict(x_train)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(\n",
    "        y_train, train_pred, pos_label=2)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "    train_results.append(roc_auc)\n",
    "    y_pred = dt.predict(x_test)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(\n",
    "        y_test, y_pred, pos_label=2)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "    test_results.append(roc_auc)\n",
    "\n",
    "line1, = plt.plot(max_depths, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(max_depths, test_results, 'r', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Tree depth')\n",
    "\n",
    "plt.savefig(\"../img/2019-07-29_决策树_1.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T12:34:18.716828Z",
     "start_time": "2019-09-09T12:34:18.560439Z"
    }
   },
   "source": [
    "![](/img/2019-07-29_决策树_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_split\n",
    "\n",
    "min_samples_split表示拆分内部节点所需的最小样本数。 这可以在考虑每个节点处的至少一个样本，并考虑每个节点处的所有样本之间变化。 当我们增加此参数时，给与树更多的约束，因为它必须在每个节点处考虑更多样本。 在这里，我们将从10％到100％的样本中改变参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T12:34:35.633374Z",
     "start_time": "2019-09-09T12:34:35.527682Z"
    }
   },
   "outputs": [],
   "source": [
    "min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_split in min_samples_splits:\n",
    "    dt = DecisionTreeClassifier(min_samples_split=min_samples_split)\n",
    "    dt.fit(x_train, y_train)\n",
    "    train_pred = dt.predict(x_train)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(\n",
    "        y_train, train_pred, pos_label=2)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_results.append(roc_auc)\n",
    "    y_pred = dt.predict(x_test)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(\n",
    "        y_test, y_pred, pos_label=2)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(min_samples_splits, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(min_samples_splits, test_results, 'r', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('min samples split')\n",
    "\n",
    "plt.savefig(\"../img/2019-07-29_决策树_2.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](/img/2019-07-29_决策树_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_leaf\n",
    "min_samples_leaf是叶节点所需的最小样本数。 此参数类似于min_samples_splits，但是，这描述了叶子（树的基础）处的样本的最小样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T12:35:14.639404Z",
     "start_time": "2019-09-09T12:35:14.498174Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_samples_leafs = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_leaf in min_samples_leafs:\n",
    "    dt = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf)\n",
    "    dt.fit(x_train, y_train)\n",
    "    train_pred = dt.predict(x_train)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(\n",
    "        y_train, train_pred, pos_label=2)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_results.append(roc_auc)\n",
    "    y_pred = dt.predict(x_test)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(\n",
    "        y_test, y_pred, pos_label=2)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(min_samples_leafs, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(min_samples_leafs, test_results, 'r', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('min samples leaf')\n",
    "\n",
    "plt.savefig(\"../img/2019-07-29_决策树_3.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T12:34:59.109702Z",
     "start_time": "2019-09-09T12:34:58.966549Z"
    }
   },
   "source": [
    "![](/img/2019-07-29_决策树_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_features\n",
    "max_features表示查找最佳拆分时要考虑的要最大特征数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T12:35:18.755107Z",
     "start_time": "2019-09-09T12:35:18.646762Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_features = list(range(1, len(iris_target_name)))\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_feature in max_features:\n",
    "    dt = DecisionTreeClassifier(max_features=max_feature)\n",
    "    dt.fit(x_train, y_train)\n",
    "    train_pred = dt.predict(x_train)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(\n",
    "        y_train, train_pred, pos_label=2)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_results.append(roc_auc)\n",
    "    y_pred = dt.predict(x_test)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(\n",
    "        y_test, y_pred, pos_label=2)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_results.append(roc_auc)\n",
    "\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "\n",
    "line1, = plt.plot(max_features, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(max_features, test_results, 'r', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('max features')\n",
    "\n",
    "plt.savefig(\"../img/2019-07-29_决策树_4.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](/img/2019-07-29_决策树_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 树的可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T12:35:22.123046Z",
     "start_time": "2019-09-09T12:35:22.044767Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "import graphviz\n",
    "import pydotplus as pdp\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file = None,\n",
    "                               feature_names = [\"标签A\",\"标签B\",\"标签C\"],\n",
    "                               class_names = [\"分类A\",\"分类B\"],\n",
    "                               filled = True,\n",
    "                               rotate = False)\n",
    "\n",
    "# 要先用brew install graphviz\n",
    "graph = pdp.graph_from_dot_data(dot_data)\n",
    "img = Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](/img/2019-07-29_决策树_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 参考：\n",
    "\n",
    "1. [从机器学习到深度学习：基于Scikit-learn与TensorFlow的高效开发实战](http://www.broadview.com.cn/book/5337)\n",
    "2. [决策树（四）决策树调参](https://www.cnblogs.com/jin-liang/p/9638197.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
